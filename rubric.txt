FEATURE - Identifying movies without quotation marks and correct capitalization (part 1): YES
FEATURE - Identifying movies without quotation marks and correct capitalization (part 2): YES
FEATURE - Alternate/foreign titles: YES
FEATURE - Disambiguation (part 1): NO
FEATURE - Fine-grained sentiment extraction: YES
FEATURE - Spell-correcting fallback for find_movies_by_title: YES
FEATURE - Extracting sentiment with multiple-movie input: YES
FEATURE - Disambiguation (part 2): NO
FEATURE - Disambiguation (part 3): NO
FEATURE - Dialogue for spell-checking: NO
FEATURE - Dialogue for disambiguation: NO
FEATURE - Communicating sentiments and movies extracted to the user given multiple-movie input: YES
FEATURE - Understanding references to things said previously: NO
FEATURE - Responding to arbitrary input: NO
FEATURE - Speaking very fluently: NO
FEATURE - Identifying and responding to emotions: NO
Did not implement any of the above features: NO

#########################################################################################
# Team Contributions                                                                    #
#########################################################################################
We believe that we all contributed pretty equally to the code, as we were all working quite synchronously 
via Zoom to implement each starter and creative mode feature. 


#########################################################################################
# Ethics Question                                                                  #
#########################################################################################

Humans are quick to anthropomorphize chatbots, like ELIZA.
In the 1960’s, users’ trust in ELIZA raised numerous concerns that humans would believe the system’s advice,
even if ELIZA did not actually know what it was talking about. Newer chatbots are built using neural networks,
like those you implemented in PA5. These neural networks are trained on enormous sets of data, from online
sources like Reddit and Twitter. These sources are interlaced with offensive text that are often reproduced
in chatbot responses. Furthermore, the newest advanced models, like GPT-3, have produced responses that appear
that they were written by a human.

What are some possible ramifications of anthropomorphizing chatbot systems? Can you think of any ways that
engineers could ensure that users can easily distinguish the chatbot responses from those of a human?

Allowing chatbot systems to be anthropomorphized by the general public can prove to be quite dangerous. This is outlined very clearly 
in the lecture video regarding ELIZA, when Weizenbaum discovered that members of his staff were having quite private conversations with ELIZA. 
Clearly there is the matter of data privacy - if chatbots are perceived as “human”, then people might be willing to share more sensitive and 
vulnerable information about themselves. More importantly, however, I think that the anthropomorphization of chatbot systems can negatively 
impact one’s mental health. “Understanding” a chatbot system to be “human” is actually a huge deal - your brain believes that a piece of software 
is “human” enough for your conversational needs. But there will inevitably come a time when the chatbot crashes, loops through the same text 
repetitively, or does something else that is very non-human. To someone who has anthropomorphized the chatbot, this could have a wide array of 
consequences (ranging from dissatisfaction or anger to low self-esteem or even heightened anxiety).

To ensure that users can easily distinguish chatbot responses from those of a human, engineers should just be as explicit as possible when releasing 
chatbots to the general public. A quick addendum to the greeting message simply stating that the software is a chatbot would suffice. And perhaps 
if the user is starting to give more sensitive information than needed to the chatbot, it could give the user a quick message explicitly reminding 
the user that they are talking to a chatbot, not a human. Anything produced by a chatbot should be easily identifiable to the chatbot itself.


#########################################################################################
# Optional: Feel free to include anything else that you want us to know about your      #
# implementation!                                                                       #
#########################################################################################
(optional) If you have anything else you want to add, delete this and type it here!
